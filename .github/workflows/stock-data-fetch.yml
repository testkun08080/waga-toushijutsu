name: ğŸ“Š Stock Data Fetch

permissions:
  contents: write
  actions: read

on:
  workflow_dispatch:
    inputs:
      stock_file:
        description: "Stock JSON file to process"
        required: true
        default: "stocks_1.json"
        type: choice
        options:
          - "stocks_1.json"
          - "stocks_2.json"
          - "stocks_3.json"
          - "stocks_4.json"
          - "stocks_temp.json"
      batch_name:
        description: "Batch identifier (for output filename)"
        required: true
        default: "batch1"
        type: string

jobs:
  fetch-stock-data:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: ğŸ”„ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
          cache: "pip"

      - name: ğŸ“¦ Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r stock_list/requirements.txt

      - name: ğŸ“‹ Show input parameters
        run: |
          echo "Processing file: ${{ github.event.inputs.stock_file }}"
          echo "Batch name: ${{ github.event.inputs.batch_name }}"
          echo "Working directory: $(pwd)"
          ls -la stock_list/

      - name: ğŸƒ Run stock data collection
        working-directory: ./stock_list
        run: |
          echo "ğŸš€ Starting stock data collection..."
          echo "File: ${{ github.event.inputs.stock_file }}"
          echo "Timestamp: $(date)"

          # Run the Python script with the selected JSON file
          python sumalize.py "${{ github.event.inputs.stock_file }}"

          echo "âœ… Stock data collection completed"

          # List generated files
          echo "ğŸ“„ Generated files:"
          ls -la japanese_stocks_data_*.csv 2>/dev/null || echo "No CSV files generated"

      - name: ğŸ“‚ Move files to Export directory
        run: |
          # Create Export directory if it doesn't exist
          mkdir -p Export

          # Move generated CSV files to Export directory with batch naming
          cd stock_list
          for file in japanese_stocks_data_*.csv; do
            if [ -f "$file" ]; then
              # Extract timestamp from original filename
              timestamp=$(echo "$file" | grep -o '[0-9]\{8\}_[0-9]\{6\}')
              # Create new filename with batch identifier
              new_name="stock_data_${{ github.event.inputs.batch_name }}_${timestamp}.csv"
              echo "ğŸ“¦ Moving $file to ../Export/$new_name"
              mv "$file" "../Export/$new_name"
            fi
          done

          # Also move log file if exists
          if [ -f "stock_data_log.txt" ]; then
            log_name="stock_data_log_${{ github.event.inputs.batch_name }}_$(date +%Y%m%d_%H%M%S).txt"
            echo "ğŸ“‹ Moving log file to ../Export/$log_name"
            mv "stock_data_log.txt" "../Export/$log_name"
          fi

          cd ..
          echo "ğŸ“ Export directory contents:"
          ls -la Export/

      - name: ğŸ“Š Generate summary report
        run: |
          cd Export
          echo "# ğŸ“Š Stock Data Collection Report" > README.md
          echo "" >> README.md
          echo "**Generated:** $(date)" >> README.md
          echo "**Batch:** ${{ github.event.inputs.batch_name }}" >> README.md
          echo "**Source File:** ${{ github.event.inputs.stock_file }}" >> README.md
          echo "**Workflow:** ${{ github.workflow }}" >> README.md
          echo "" >> README.md
          echo "## ğŸ“„ Generated Files" >> README.md
          echo "" >> README.md

          for file in stock_data_*.csv; do
            if [ -f "$file" ]; then
              size=$(ls -lh "$file" | awk '{print $5}')
              lines=$(wc -l < "$file")
              echo "- **$file** - Size: $size, Records: $((lines-1))" >> README.md
            fi
          done

          if [ -f "stock_data_log_*.txt" ]; then
            echo "" >> README.md
            echo "## ğŸ“‹ Log Files" >> README.md
            for logfile in stock_data_log_*.txt; do
              if [ -f "$logfile" ]; then
                size=$(ls -lh "$logfile" | awk '{print $5}')
                echo "- **$logfile** - Size: $size" >> README.md
              fi
            done
          fi

          echo "" >> README.md
          echo "## ğŸ¤– Automation Info" >> README.md
          echo "- **GitHub Action:** [${{ github.workflow }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> README.md
          echo "- **Commit SHA:** ${{ github.sha }}" >> README.md
          echo "- **Repository:** ${{ github.repository }}" >> README.md

      - name: ğŸ”§ Configure Git
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"

            - name: ğŸ’¾ Commit and push changes
        run: |
          # Clean working directory to avoid unstaged changes
          git reset --hard
          git clean -fd
          
          # Pull latest main
          git pull --rebase origin main
          
          # Add all new files in Export directory
          git add Export/

          if git diff --staged --quiet; then
            echo "â„¹ï¸ No changes to commit"
          else
            git commit -m "ğŸ“Š Update stock data: ${{ github.event.inputs.batch_name }} from ${{ github.event.inputs.stock_file }}

            - Processed: ${{ github.event.inputs.stock_file }}
            - Batch: ${{ github.event.inputs.batch_name }}
            - Generated: $(date)
            - Workflow: ${{ github.workflow }}
            
            ğŸ¤– Generated by GitHub Action"
            
            git push
            echo "âœ… Changes committed and pushed successfully"
          fi

      - name: ğŸ“ˆ Upload artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: stock-data-${{ github.event.inputs.batch_name }}
          path: |
            Export/stock_data_*.csv
            Export/stock_data_log_*.txt
            Export/README.md
          retention-days: 30
