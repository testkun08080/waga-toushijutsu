#!/usr/bin/env python3
"""
Latest CSV Combiner for Japanese Stock Data
æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆã—ã¦æ—¥ä»˜ä»˜ãã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Purpose:
- Exportãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
- è¤‡æ•°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆã—ã¦ä¸€ã¤ã®çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
- æ—¥ä»˜_combined.csvå½¢å¼ã§ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
"""

import os
import glob
import pandas as pd
from datetime import datetime
import argparse
import logging
from pathlib import Path

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('combine_csv.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def get_latest_csv_files(export_dir="./Export"):
    """
    Exportãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—

    Args:
        export_dir (str): CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

    Returns:
        list: æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
    """
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®šç¾©
    pattern = os.path.join(export_dir, "japanese_stocks_data_*.csv")
    csv_files = glob.glob(pattern)

    if not csv_files:
        logger.warning(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
        return []

    # ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆæœ€æ–°é †ï¼‰
    csv_files.sort(key=os.path.getmtime, reverse=True)

    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
    logger.info(f"ç™ºè¦‹ã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«: {len(csv_files)}å€‹")
    for i, file in enumerate(csv_files):
        mod_time = datetime.fromtimestamp(os.path.getmtime(file))
        logger.info(f"  {i+1}. {os.path.basename(file)} (æ›´æ–°æ—¥æ™‚: {mod_time})")

    return csv_files

def get_today_date():
    """
    ä»Šæ—¥ã®æ—¥ä»˜ã‚’YYYYMMDDå½¢å¼ã§å–å¾—

    Returns:
        str: ä»Šæ—¥ã®æ—¥ä»˜ï¼ˆYYYYMMDDå½¢å¼ï¼‰
    """
    return datetime.now().strftime("%Y%m%d")

def combine_csv_files(csv_files, output_file):
    """
    è¤‡æ•°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆã—ã¦ä¸€ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜

    Args:
        csv_files (list): çµåˆã™ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
        output_file (str): å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å

    Returns:
        bool: æˆåŠŸã—ãŸå ´åˆTrueã€å¤±æ•—ã—ãŸå ´åˆFalse
    """
    try:
        combined_data = []
        total_rows = 0

        for csv_file in csv_files:
            logger.info(f"èª­ã¿è¾¼ã¿ä¸­: {os.path.basename(csv_file)}")

            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰
            df = pd.read_csv(csv_file, encoding='utf-8')

            # BOMï¼ˆByte Order Markï¼‰ã‚’é™¤å»
            if df.columns[0].startswith('\ufeff'):
                df.columns = [df.columns[0].replace('\ufeff', '')] + df.columns[1:].tolist()

            # ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
            logger.info(f"  - è¡Œæ•°: {len(df)}, åˆ—æ•°: {len(df.columns)}")

            combined_data.append(df)
            total_rows += len(df)

        if not combined_data:
            logger.error("çµåˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return False

        # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆï¼ˆé‡è¤‡æ’é™¤ï¼‰
        logger.info("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆä¸­...")
        combined_df = pd.concat(combined_data, ignore_index=True)

        # é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã®é™¤å»ï¼ˆéŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ï¼‰
        if 'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰' in combined_df.columns:
            before_dedup = len(combined_df)
            combined_df = combined_df.drop_duplicates(subset=['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'], keep='last')
            after_dedup = len(combined_df)
            logger.info(f"é‡è¤‡é™¤å»: {before_dedup} â†’ {after_dedup} è¡Œ ({before_dedup - after_dedup}è¡Œã‚’é™¤å»)")

        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(os.path.dirname(output_file), exist_ok=True)

        # çµåˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        combined_df.to_csv(output_file, index=False, encoding='utf-8')

        logger.info(f"âœ… çµåˆå®Œäº†: {output_file}")
        logger.info(f"   - ç·è¡Œæ•°: {len(combined_df)}")
        logger.info(f"   - ç·åˆ—æ•°: {len(combined_df.columns)}")
        logger.info(f"   - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {os.path.getsize(output_file) / (1024*1024):.2f} MB")

        return True

    except Exception as e:
        logger.error(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«çµåˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
        return False

def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    """
    parser = argparse.ArgumentParser(description='æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆã—ã¦æ—¥ä»˜ä»˜ããƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ')
    parser.add_argument('--export-dir', default='./Export',
                       help='CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ./Export)')
    parser.add_argument('--output-dir', default='./Export',
                       help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ./Export)')
    parser.add_argument('--date', default=None,
                       help='ä½¿ç”¨ã™ã‚‹æ—¥ä»˜ (YYYYMMDDå½¢å¼ã€æœªæŒ‡å®šã®å ´åˆã¯ä»Šæ—¥ã®æ—¥ä»˜)')
    parser.add_argument('--max-files', type=int, default=None,
                       help='çµåˆã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€å¤§æ•°ï¼ˆæœªæŒ‡å®šã®å ´åˆã¯å…¨ã¦ï¼‰')

    args = parser.parse_args()

    # å®Ÿè¡Œé–‹å§‹ãƒ­ã‚°
    logger.info("=" * 60)
    logger.info("ğŸš€ Latest CSV Combiner å®Ÿè¡Œé–‹å§‹")
    logger.info("=" * 60)

    # æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    csv_files = get_latest_csv_files(args.export_dir)

    if not csv_files:
        logger.error("âŒ çµåˆã™ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False

    # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚’åˆ¶é™ï¼ˆæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
    if args.max_files and args.max_files > 0:
        csv_files = csv_files[:args.max_files]
        logger.info(f"ğŸ“‹ çµåˆå¯¾è±¡ã‚’æœ€æ–°{args.max_files}ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ¶é™")

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
    date_str = args.date if args.date else get_today_date()
    output_filename = f"{date_str}_combined.csv"
    output_path = os.path.join(args.output_dir, output_filename)

    logger.info(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
    success = combine_csv_files(csv_files, output_path)

    if success:
        logger.info("=" * 60)
        logger.info("âœ… CSVçµåˆå‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        logger.info("=" * 60)
        print(f"OUTPUT_FILE={output_path}")  # GitHub Actionsç”¨ã®å‡ºåŠ›
        return True
    else:
        logger.error("=" * 60)
        logger.error("âŒ CSVçµåˆå‡¦ç†ãŒå¤±æ•—ã—ã¾ã—ãŸ")
        logger.error("=" * 60)
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)